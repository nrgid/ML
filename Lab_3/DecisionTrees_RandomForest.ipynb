{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this session, we will build a spam classification by using an email dataset. Our goal is to develop optimal models to predict whether an email is spam or not spam based on word characteristics within each email. \n",
        "We have to perform the following steps:\n",
        "\n",
        "\n",
        "1.   Prepare data\n",
        "2.   Find the optimal depth for the Decision Tree model and evaluate performance.\n",
        "3. Fit the Bagging model using multiple bootstrapped datasets and ensemble.\n",
        "4. Fit a Random Forest model.\n",
        "5. Explore the Bias vs Variance tradeoff."
      ],
      "metadata": {
        "id": "u0HCGqEU0U4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: prepare your dataset"
      ],
      "metadata": {
        "id": "i1pUyKhP1ZFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score,roc_curve\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jn6sqkJR2GSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "df =pd.read_csv(\"drive/My Drive/Colab Notebooks/Lab3_dataset1.csv\")\n",
        "columns = [\"Column_\"+str(i+1) for i in range(df.shape[1]-1)] + ['Spam']\n",
        "df.columns = columns\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YEdsRJHk4BO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test\n",
        "np.random.seed(10)\n",
        "indx = np.random.rand(len(df)) < 0.7\n",
        "print(indx)\n",
        "df_train = df[indx]\n",
        "df_test = df[~indx]\n",
        "\n",
        "#Split predictor and response columns\n",
        "x_train, y_train = df_train.drop(['Spam'], axis=1), df_train['Spam']\n",
        "x_test, y_test = df_test.drop(['Spam'], axis=1), df_test['Spam']\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)\n",
        "\n",
        "#Check Percentage of Spam in Train and Test Set\n",
        "print(\"Percentage of Spam in Training Set :\", str(100*y_train.sum()/len(y_train))+'%')\n",
        "print(\"Percentage of Spam in Testing Set :\",str(100*y_test.sum()/len(y_test))+'%')\n",
        "\n"
      ],
      "metadata": {
        "id": "Sp7xBLAeLAqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train your Decision Tree model"
      ],
      "metadata": {
        "id": "AHb88m2EM9hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning of the parameter depth: find optimal depth of trees\n",
        "depth= {}\n",
        "tree_start, tree_end = 3, 30\n",
        "for i in range(tree_start, tree_end):\n",
        "    model = DecisionTreeClassifier(max_depth=i)\n",
        "    scores = cross_val_score(estimator=model, X=x_train, y=y_train, cv=5, n_jobs=-1)\n",
        "    depth[i] = scores.mean()\n",
        "    \n",
        "#Plot of results\n",
        "print(depth)\n",
        "lists = sorted(depth.items())\n",
        "x, y = zip(*lists) \n",
        "y_err = scores.std()\n",
        "plt.ylabel(\"Cross Validation Accuracy\")\n",
        "plt.xlabel(\"Maximum Depth\")\n",
        "plt.title('Variation of Accuracy with Depth for Decision Tree Model')\n",
        "plt.plot(x, y, 'k-', marker='o')\n",
        "plt.fill_between(x, y - y_err, y + y_err, color='grey', alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oZaejeHNJkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make best depth a variable\n",
        "best_depth = sorted(depth, key=depth.get, reverse=True)[0]\n",
        "print(\"The best depth is:\", best_depth)"
      ],
      "metadata": {
        "id": "C_zGB_XlOZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evalaute the performance choosing the best depth\n",
        "model = DecisionTreeClassifier(max_depth=best_depth)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#Check Accuracy of Spam Detection in Train and Test Set\n",
        "print(\"Accuracy, Training Set: {:.1%}\".format(accuracy_score(y_train, model.predict(x_train))))\n",
        "print(\"Accuracy, Testing Set: {:.1%}\".format(accuracy_score(y_test, model.predict(x_test))))"
      ],
      "metadata": {
        "id": "-VZvq53PSLtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, model.predict(x_test))\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()\n",
        "\n",
        "pd.crosstab(y_test, model.predict(x_test), margins=True, rownames=['Actual'], colnames=['Predicted'])"
      ],
      "metadata": {
        "id": "xAuljO5AS6ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = model.predict_proba(x_test)[:,1]\n",
        "print(\"Roc AUC:\", roc_auc_score(y_test, model.predict_proba(x_test)[:,1],average='macro'))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr, label='Decision Tree')\n",
        "plt.plot([0, 1], ls=\"--\",label='Chance level')\n",
        "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "Mlhxk-tA4NRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Bagging"
      ],
      "metadata": {
        "id": "882r5UEnTcVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating model\n",
        "np.random.seed(0)\n",
        "model = DecisionTreeClassifier(max_depth=5) \n",
        "\n",
        "#Initializing variables\n",
        "n_trees = 100 \n",
        "predictions_train = np.zeros((df_train.shape[0], n_trees))\n",
        "predictions_test = np.zeros((df_test.shape[0], n_trees))\n",
        "\n",
        "#Bootstraping iterations\n",
        "for i in range(n_trees):\n",
        "    temp_sample = df_train.sample(frac=1, replace=True)\n",
        "    response_variable = temp_sample['Spam']\n",
        "    temp_sample = temp_sample.drop(['Spam'], axis=1)\n",
        "    model.fit(temp_sample, response_variable)  \n",
        "    predictions_train[:,i] = model.predict(x_train)   \n",
        "    predictions_test[:,i] = model.predict(x_test)\n",
        "    \n",
        "#Make Predictions Dataframe\n",
        "columns = [\"Bootstrap-Model_\"+str(i+1) for i in range(n_trees)]\n",
        "predictions_train = pd.DataFrame(predictions_train, columns=columns)\n",
        "predictions_test = pd.DataFrame(predictions_test, columns=columns)\n",
        "print(predictions_train.shape)\n",
        "print(predictions_test.shape)"
      ],
      "metadata": {
        "id": "qTv8TsBhUp3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['Spam'].values\n",
        "y_test = df_test['Spam'].values\n",
        "\n",
        "# n_trees\n",
        "num_to_avg = 100 \n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
        "for (ax, label, predictions, y) in [\n",
        "    (axs[0], 'Train', predictions_train, y_train), \n",
        "    (axs[1], 'Test', predictions_test, y_test)\n",
        "]:\n",
        "    mean_predictions = predictions.iloc[:,:num_to_avg].mean(axis=1)\n",
        "    mean_predictions[y == 1].hist(density=True, histtype='step', range=[0,1], label='Spam', lw=2, ax=ax)\n",
        "    mean_predictions[y == 0].hist(density=True, histtype='step', range=[0,1], label='Not-Spam', lw=2, ax=ax)\n",
        "    ax.legend(loc='upper center');\n",
        "    ax.set_xlabel(\"Mean of ensemble predictions\")\n",
        "    ax.set_title(label)"
      ],
      "metadata": {
        "id": "O9w72-osWE54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to ensemble the prediction of each bagged decision tree model\n",
        "def get_prediction(df, count=-1):\n",
        "    count = df.shape[1] if count==-1 else count\n",
        "    temp = df.iloc[:,0:count]\n",
        "    return np.mean(temp, axis=1)>0.5\n",
        "\n",
        "#Check performance metrics of Spam Detection in Test Set\n",
        "\n",
        "Accuracy = metrics.accuracy_score(y_test, get_prediction(predictions_test, count=-1))\n",
        "Sensitivity = metrics.recall_score(y_test, get_prediction(predictions_test, count=-1))\n",
        "Specificity = metrics.recall_score(y_test, get_prediction(predictions_test, count=-1),pos_label=0)\n",
        "F1_score = metrics.f1_score(y_test, get_prediction(predictions_test, count=-1))\n",
        "\n",
        "print({\"Accuracy\":Accuracy,\"Sensitivity\":Sensitivity,\"Specificity\":Specificity,\"F1_score\":F1_score})\n"
      ],
      "metadata": {
        "id": "SoDsGYIsZpsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, get_prediction(predictions_test, count=-1))\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eB7DEi1ldT_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit a Random Forest Model\n",
        "\n",
        "#Training\n",
        "model = RandomForestClassifier(n_estimators=int(math.sqrt(x_train.shape[1])), max_depth=best_depth)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#Predict\n",
        "y_pred_train = model.predict(x_train)\n",
        "y_pred_test = model.predict(x_test)\n",
        "\n",
        "#Performance metrics\n",
        "train_score = accuracy_score(y_train, y_pred_train)*100\n",
        "test_score = accuracy_score(y_test, y_pred_test)*100\n",
        "\n",
        "print(\"Accuracy, Training Set :\",str(train_score)+'%')\n",
        "print(\"Accuracy, Testing Set :\",str(test_score)+'%')"
      ],
      "metadata": {
        "id": "tqX3Db7qfKia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top Features\n",
        "feature_importance = model.feature_importances_\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, x_train.columns[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Variable Importance')"
      ],
      "metadata": {
        "id": "j7TSpipegVi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Learning Curve for training\n",
        "estimator = RandomForestClassifier(n_estimators=int(math.sqrt(x_train.shape[1])), max_depth=best_depth)\n",
        "title = \"Learning Curves (Random Forest)\"\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(estimator, x_train, y_train, cv=5,scoring=\"accuracy\", train_sizes=np.linspace(0.01, 1.0, 50))\n",
        "\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.subplots(1, figsize=(10,10))\n",
        "plt.plot(train_sizes, train_mean, '--', color=\"red\",  label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, color=\"black\", label=\"Cross-validation score\")\n",
        "\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"red\", alpha=0.3)\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"gray\",alpha=0.3)\n",
        "\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nDn8oXdxgmpf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}